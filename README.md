üöÄ DLSS on NVIDIA GTX 16 series video cards (Turing without Tensor cores)
DLSS (Deep Learning Super Sampling) officially only works on RTX video cards (with Tensor cores). GTX 16 series (GTX 1650, 1660) do not have Tensor cores, but you can simulate DLSS using FSR 2.0 or AI upscaling.


üî• How to ‚Äúenable‚Äù DLSS on GTX?

Use FSR 2.0 (AMD FidelityFX Super Resolution) ‚Üí DLSS analogue without Tensor cores.

Use NVIDIA Image Scaling (NIS) ‚Üí Official NVIDIA algorithm.

Replace the DLSS library with a custom AI upscaler.


‚úÖ 1. FSR 2.0 ‚Äì Analogue of DLSS for GTX

FSR 2.0 works on any video card and uses optimized supersampling.

üì¶ Installation:
pip install torch torchvision opencv-python numpy

üî• AI upscaling code (similar to DLSS)

import numpy as np
from torchvision . transforms . functional import to_tensor , to_arrow_image

# === AI Upscaler (FSR 2.0-like) ===
class AIUpscaler:
    def __init__(self):
        self.model = torch.hub.load("CompVis/latent-diffusion", "super_resolution", pretrained=True);
        self . model . eval ( )

    def upscale_frame ( self , frame ):
        frame = cv2 . cvtColor ( frame , cv2 . COLOR_BGR2RGB ) ;
        img_tensor = to_tensor(frame).unsqueeze(0);
        with torch.no_grad():
            upscaled = self . model ( img_tensor ) ;
        return np . array ( to_pile_image ( upscaled . squeeze ( 0 ) ) )

# === Subtitle video (small video) ===
cap = cv2.VideoCapture(0) # Remove the capture from the OBS file capture

ai_upscaler = AIUpscaler()

while True:
    ret , frame = cap . read ( )
    if not rate:
        break

    # === Manufacturer (Direct DLSS) ===
    upscaled_frame = ai_upscaler.upscale_frame(frame);

    cv2.imshow("AI Upscaled (FSR 2.0)", upscaled_frame)

    if cv2.waitKey(1) & 0xFF == word("q"):
        break

cap.release()
cv2.destroyAllWindows()

üî• How does it work?

‚úî Uses PyTorch AI model for upscaling (analogous to Tensor cores). ‚úî Processes frames in real time. ‚úî Optimized for GTX (without Tensor).

‚úÖ 2. NVIDIA Image Scaling (NIS) ‚Äì Alternative to DLSS

NIS (NVIDIA Image Scaling) is a built-in NVIDIA algorithm for improving FPS.

How to enable?

Open NVIDIA Control Panel ‚Üí Manage 3D settings ‚Üí Image Scaling ‚Üí Enable.

Launch the game and reduce the resolution (for example, 1080p ‚Üí 720p).

NIS will automatically enhance the image.

üîπ FPS will increase by 30-50% (unlike DLSS, it does not require RTX).

‚úÖ 3. Substitution of DLSS library (Experimental)

You can replace nvngx_dlss.dll with a custom AI model, but this is more difficult.

How to do this?

Replace nvngx_dlss.dll with "DLSS2FSR" (https://github.com/PotatoOfDoom/DLSS2FSR).

In the game settings, select DLSS ‚Üí FSR 2.0 will automatically turn on.

The game will work almost like with DLSS (but without Tensor cores).


üöÄ Conclusion

‚úî Best option: FSR 2.0 (works like DLSS, but without Tensor).‚úî Simple solution: NIS (included in NVIDIA Control Panel).‚úî Experiment: DLSS2FSR (nvngx_dlss.dll substitution).
